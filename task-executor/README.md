# Task Executor

RESTful API for scalable AIOpsLab task execution with integrated worker management.

## å½“å‰ç†è§£ã€ç›®æ ‡ä¸ç°çŠ¶

### æˆ‘ä»¬å¯¹ Task Executor çš„ç†è§£
- æä¾› FastAPI é©±åŠ¨çš„ä»»åŠ¡æ‰§è¡ŒæœåŠ¡ï¼Œå°†å¤–éƒ¨æäº¤çš„ AIOpsLab é—®é¢˜æ’é˜Ÿã€è°ƒåº¦å¹¶è®°å½•æ‰§è¡Œå…¨æµç¨‹ã€‚
- é€šè¿‡æ•°æ®åº“é©±åŠ¨çš„ä»»åŠ¡é˜Ÿåˆ— (`SELECT FOR UPDATE SKIP LOCKED`) ä¸ REST æ¥å£è¿æ¥å¤–éƒ¨è°ƒç”¨æ–¹ä¸å†…éƒ¨/å¤–éƒ¨ workerã€‚
- åœ¨åŒä¸€è¿›ç¨‹å†…æ‰˜ç®¡ `WorkerManager`ï¼Œè‡ªåŠ¨æ‹‰èµ·å†…éƒ¨ worker å¹¶å¯é€‰è°ƒç”¨çœŸå®çš„ AIOpsLab Orchestratorã€‚

### å½“å‰ç›®æ ‡
- æš´éœ²ç¨³å®šçš„ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸ APIï¼ˆåˆ›å»ºã€æŸ¥è¯¢ã€å–æ¶ˆã€æ—¥å¿—ã€ç»Ÿè®¡ï¼‰ï¼Œä¾›ä¸Šå±‚åœ¨çº¿ RL / Agent ç»„ä»¶å¤ç”¨ã€‚
- ä¿è¯ worker ä¸ä»»åŠ¡ä¹‹é—´çš„ç»‘å®šä¸è°ƒåº¦ç­–ç•¥æ»¡è¶³è§„æ ¼ä¸­â€œä¸€å¯¹ä¸€ backend æ˜ å°„ã€Kind éš”ç¦»â€çš„è¦æ±‚ã€‚
- ç»´æŒå¯è§‚æµ‹æ€§ï¼šPrometheus `/metrics`ã€ç»“æ„åŒ–æ—¥å¿—ã€LLM ä¼šè¯ç•™å­˜ã€‚
- ä¸ºåç»­æ‰©å±•ï¼ˆå¤šåç«¯ workerã€çœŸå® orchestratorã€LLM å›è¯å¯è§†åŒ–ï¼‰æ‰“å¥½æ•°æ®æ¨¡å‹å’ŒæœåŠ¡æ¥å£åŸºç¡€ã€‚

### ç³»ç»Ÿç°çŠ¶ï¼ˆ2025-09-17ï¼‰
- âœ… APIã€ä»»åŠ¡é˜Ÿåˆ—ã€æ•°æ®æ¨¡å‹ã€å†…éƒ¨ worker æ¡†æ¶å‡å·²å®ç°å¹¶å¯å¯åŠ¨ã€‚
- âš ï¸ å·²çŸ¥æŠ€æœ¯å€ºï¼š
  - `/metrics` ç«¯ç‚¹ä½¿ç”¨ `async with get_db()` ä¼šæŠ›é”™ï¼ŒPrometheus å½“å‰ä¸å¯ç”¨ã€‚
  - Worker å®Œæˆ/å¤±è´¥æ¥å£ç¼ºä¹ä»»åŠ¡å½’å±æ ¡éªŒï¼Œå­˜åœ¨è¶Šæƒé£é™©ã€‚
  - `LLMLoggingAgent` å¯¹å¼‚æ­¥ Agent å¤„ç†ä¸å½“ï¼Œæ‰§è¡ŒçœŸå® orchestrator æ—¶ä¼šæŠ› `TypeError`ã€‚
  - `OrchestratorExecutor` åœ¨äº‹ä»¶å¾ªç¯å†…æ‰§è¡Œé˜»å¡æ“ä½œï¼ˆKind ç®¡ç†ã€`orchestrator.run()`ï¼‰ï¼Œå¯èƒ½å¡æ­»æ•´ä¸ª APIã€‚
  - ä»»åŠ¡åˆ†é…æš‚æœªä¾æ® worker backend/capabilities è¿‡æ»¤ï¼Œæ— æ³•æ»¡è¶³è§„æ ¼ä¸­çš„èƒ½åŠ›çº¦æŸã€‚
- ğŸ› ï¸ ä¸‹ä¸€æ­¥ä¼šä¼˜å…ˆä¿®å¤ä¸Šè¿°é«˜ä¼˜å…ˆçº§é—®é¢˜ï¼Œå¹¶è¡¥å……æµ‹è¯•/æ–‡æ¡£ã€‚

## Architecture

```
task-executor/
â”œâ”€â”€ api/                    # RESTful API Server with integrated workers
â”‚   â”œâ”€â”€ src/               # Source code
â”‚   â”‚   â”œâ”€â”€ api/          # API endpoints
â”‚   â”‚   â”œâ”€â”€ models/       # Database models
â”‚   â”‚   â”œâ”€â”€ services/     # Business logic
â”‚   â”‚   â”œâ”€â”€ schemas/      # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ lib/          # Libraries (task queue)
â”‚   â”‚   â””â”€â”€ workers/      # Internal worker management
â”‚   â”œâ”€â”€ tests/            # Test suites
â”‚   â””â”€â”€ pyproject.toml    # Python dependencies (Poetry)
```

## Key Changes from Previous Version

âœ¨ **Workers are now integrated into the API process** - No need to manually start separate worker processes. The API automatically manages internal workers as background tasks.

## Components

### API Server with Integrated Workers
- **Framework**: FastAPI with async support
- **Database**: PostgreSQL with SQLAlchemy ORM
- **Task Queue**: Database-backed queue using SELECT FOR UPDATE SKIP LOCKED
- **Workers**: Internal background tasks managed by the API
- **Monitoring**: Prometheus metrics and structured logging

## Key Features

- **Integrated Workers**: Workers run as background tasks within the API process
- **Auto-scaling**: Dynamic worker scaling via API endpoints
- **Atomic Task Claiming**: SELECT FOR UPDATE SKIP LOCKED prevents race conditions
- **Comprehensive Monitoring**: Metrics, logs, and real-time status
- **Flexible Configuration**: Environment variables for all settings
- **Automatic Recovery**: Timeout handling and error recovery
- **Real Orchestrator Integration**: Workers canè°ƒåº¦çœŸå® AIOpsLab Orchestratorï¼Œè‡ªåŠ¨ç®¡ç† Kind é›†ç¾¤å¹¶è®°å½• LLM ä¼šè¯

## Quick Start

```bash
# 1. Start PostgreSQL
docker-compose up -d

# 2. Install dependencies
cd api
poetry install

# 3. Start API (workers start automatically!)
poetry run uvicorn src.main:app --reload --host 0.0.0.0 --port 8000
```

That's it! The API will automatically start 3 internal workers by default.

### æ•°æ®åˆå§‹åŒ– / æ¸…ç†

è¦ä¿è¯å¯¼å‡ºçš„è½¨è¿¹å…¨éƒ¨æ¥æºäºçœŸå®è¿è¡Œï¼Œå¯åœ¨ PostgreSQL ä¸­æ¸…ç©ºç°æœ‰è®°å½•ï¼š

```bash
docker exec -i aiopslab_postgres psql -U aiopslab -d aiopslab <<'SQL'
TRUNCATE TABLE llm_conversations CASCADE;
TRUNCATE TABLE task_logs CASCADE;
TRUNCATE TABLE tasks CASCADE;
TRUNCATE TABLE workers CASCADE;
SQL
```

ï¼ˆæ³¨æ„ï¼šè¿™ä¼šåˆ é™¤æ‰€æœ‰å†å²æ•°æ®ï¼Œè¯·åœ¨æ‰§è¡Œå‰ç¡®è®¤å·²å¤‡ä»½ã€‚ï¼‰

## Configuration

Create a `.env` file in the `api` directory:

```bash
# Database
DATABASE_URL=postgresql+asyncpg://aiopslab:aiopslab@localhost:5432/aiopslab

# Worker Settings
NUM_INTERNAL_WORKERS=3      # Number of workers to start
AUTO_START_WORKERS=true      # Auto-start workers on API startup

# Task Settings
DEFAULT_TIMEOUT_MINUTES=30   # Task timeout
DEFAULT_MAX_STEPS=30         # Max steps for task execution
```

## API Endpoints

### Tasks
- `POST /api/v1/tasks` - Create new task
- `GET /api/v1/tasks` - List tasks with filtering
- `GET /api/v1/tasks/{id}` - Get task details
- `PUT /api/v1/tasks/{id}/cancel` - Cancel task
- `GET /api/v1/tasks/{id}/logs` - Get task logs
- `GET /api/v1/tasks/stats` - Queue statistics

### Workers
- `GET /api/v1/workers` - List all workers
- `GET /api/v1/workers/{id}` - Get worker details
- `GET /api/v1/workers/{id}/stats` - Worker statistics

### Internal Worker Control
- `GET /api/v1/workers/internal/status` - Internal worker status
- `POST /api/v1/workers/internal/scale?num_workers=N` - Scale workers
- `POST /api/v1/workers/internal/stop` - Stop all workers
- `POST /api/v1/workers/internal/start` - Start workers

### Monitoring
- `GET /health` - Health check
- `GET /metrics` - Prometheus metrics

## æ•°æ®å¯¼å‡º

æä¾›è„šæœ¬ `scripts/export_task_data.py` ç”¨äºé€šè¿‡ REST API æ‰¹é‡å¯¼å‡ºä»»åŠ¡ã€æ—¥å¿—å’Œ LLM ä¼šè¯ï¼š

```bash
# å¯¼å‡ºåˆ° tmp/export.jsonï¼Œé»˜è®¤åŒ…å«ä»»åŠ¡æ—¥å¿—å’Œä¼šè¯
scripts/export_task_data.py http://localhost:8000 --output tmp/export.json

# ä»…å¯¼å‡ºæœ€è¿‘ 100 æ¡ä»»åŠ¡ï¼Œä¸åŒ…å«ä¼šè¯
scripts/export_task_data.py http://localhost:8000 --max-tasks 100 --skip-conversations
```

è„šæœ¬é»˜è®¤ä½¿ç”¨ Python 3.11ï¼Œå¯é€šè¿‡ `--page-size`ã€`--max-tasks` ç­‰å‚æ•°æ§åˆ¶åˆ†é¡µï¼Œè¾“å‡ºæ–‡ä»¶ä¸ºç»“æ„åŒ– JSONï¼Œä¾¿äºåç»­ RL æ•°æ®ç®¡çº¿æ¶ˆè´¹ã€‚å¦‚å‘½ä»¤æç¤ºç¼ºå°‘ä¾èµ–ï¼Œå¯è¿è¡Œ `pip install requests` å®‰è£…æ‰€éœ€åº“ã€‚

### è¿è¡ŒçœŸå® Orchestrator

è¦å¯ç”¨çœŸå® orchestrator æ‰§è¡Œï¼Œéœ€è¦ï¼š

1. å®‰è£…å¹¶é…ç½® `kind`ã€`kubectl`ï¼ˆç¡®ä¿ Docker/k8s ç¯å¢ƒå¯ç”¨ï¼‰ï¼›
2. åœ¨ `.env` ä¸­æä¾› LLM å‡­è¯ï¼ˆå¦‚ `OPENAI_API_KEY` æˆ– `OPENROUTER_API_KEY`ï¼‰ï¼›
3. ä¿æŒ `AUTO_START_WORKERS=true`ã€`ENABLE_BACKGROUND_TASKS=true`ï¼ˆé»˜è®¤ï¼‰ï¼Œå¯åŠ¨ APIï¼š

   ```bash
   AUTO_START_WORKERS=true ENABLE_BACKGROUND_TASKS=true \
   DATABASE_URL=postgresql+asyncpg://aiopslab:aiopslab@localhost:5432/aiopslab \
   uvicorn src.main:app --host 0.0.0.0 --port 8000
   ```

4. æäº¤ä»»åŠ¡æ—¶æŒ‡å®šæœŸæœ›åç«¯ï¼ˆé»˜è®¤ `internal`ï¼Œå¦‚éœ€ä¸“é—¨ orchestrator worker å¯è®¾ç½®ä¸º `orchestrator`ï¼‰ï¼š

   ```bash
   curl -X POST http://localhost:8000/api/v1/tasks \
     -H "Content-Type: application/json" \
     -d '{
           "problem_id": "misconfig_app_hotel_res-detection-1",
           "parameters": {
             "backend_type": "internal",
             "agent_config": {"model": "gpt-4o"}
           }
         }'
   ```

æ³¨å†Œè‡ªå®šä¹‰ worker æ—¶ï¼Œå¯å°† `backend_type` è®¾ç½®ä¸º `orchestrator` å¹¶åœ¨ `capabilities.supported_problems` ä¸­åˆ—å‡ºå¯å¤„ç†çš„é—®é¢˜ï¼›é˜Ÿåˆ—ä»…ä¼šåˆ†å‘åŒ¹é…åç«¯çš„ä»»åŠ¡ã€‚

## Testing the System

Run the integrated test script:

```bash
cd task-executor
python test_integrated.py
```

This will:
1. Check API health
2. Verify workers are running
3. Submit test tasks
4. Monitor task completion
5. Test worker scaling

## Task Submission Example

```python
import aiohttp
import asyncio

async def submit_task():
    async with aiohttp.ClientSession() as session:
        task_data = {
            "problem_id": "test-problem-001",
            "parameters": {
                "max_steps": 10,
                "agent_config": {"name": "test-agent"}
            },
            "priority": 5
        }

        async with session.post(
            "http://localhost:8000/api/v1/tasks",
            json=task_data
        ) as resp:
            task = await resp.json()
            print(f"Task created: {task['id']}")

asyncio.run(submit_task())
```

## Worker Scaling Examples

```bash
# Scale to 10 workers
curl -X POST "http://localhost:8000/api/v1/workers/internal/scale?num_workers=10"

# Check worker status
curl "http://localhost:8000/api/v1/workers/internal/status"

# Stop all workers
curl -X POST "http://localhost:8000/api/v1/workers/internal/stop"
```

## Development

```bash
# Run tests
make test

# TDD mode
make tdd

# Format code
poetry run black src/

# Type check
poetry run pyright src/
```

## Database Schema

- **tasks**: Task queue and execution results
- **workers**: Worker registration and status
- **task_logs**: Detailed task execution logs

## Architecture Benefits

The integrated worker approach provides:

1. **Simplicity**: Single process to manage
2. **Efficiency**: Shared memory and resources
3. **Control**: Direct API control over workers
4. **Monitoring**: Unified logs and metrics
5. **Deployment**: Easier containerization and deployment
